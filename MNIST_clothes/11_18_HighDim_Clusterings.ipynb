{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basically a playground of trying out new ideas\n",
    "Ideas: \n",
    "- visualize output of a convolution as a changing heatmap? \n",
    "- figure out why a lot of these relational values decrease with training\n",
    "- could honestly look at something like silhoutte once project w/TSNE since it's a measure of overlap more than anythign? \n",
    "- check out the relational metrics when clustering/projecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_e0_l1 = np.load(\"layer1_epoch_0.npy\")\n",
    "weights_e1_l1 = np.load(\"layer1_epoch_1.npy\")\n",
    "weights_e2_l1 = np.load(\"layer1_epoch_2.npy\")\n",
    "weights_e3_l1 = np.load(\"layer1_epoch_3.npy\")\n",
    "weights_all_l1 = [weights_e0_l1, weights_e1_l1, weights_e2_l1, weights_e3_l1]\n",
    "#weights_e4 = np.load(\"layer1_epoch_4.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_e0_l2 = np.load(\"layer2_epoch_0.npy\")\n",
    "weights_e1_l2 = np.load(\"layer2_epoch_1.npy\")\n",
    "weights_e2_l2 = np.load(\"layer2_epoch_2.npy\")\n",
    "weights_e3_l2 = np.load(\"layer2_epoch_3.npy\")\n",
    "weights_all_l2 = [weights_e0_l2, weights_e1_l2, weights_e2_l2, weights_e3_l2]\n",
    "#weights_e4 = np.load(\"layer1_epoch_4.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c7de5e1167de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfashion_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m (train_images, train_labels), (test_images,\n\u001b[1;32m      4\u001b[0m                                test_labels) = fashion_mnist.load_data()\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images,\n",
    "                               test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(-1, 784)\n",
    "test_images = test_images.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do the principal components vary throughout training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "label_c = np.array([i for i in range(10)])\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1: 500 neurons, first dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0 \n",
    "first_comp_ratios_l1 = []\n",
    "for weight in weights_all_l1: \n",
    "    comps = pca.fit(weight)\n",
    "    first_comp_ratios_l1.append(comps.explained_variance_ratio_[0])\n",
    "    print(comps.explained_variance_ratio_[0])\n",
    "    plt.title(\"epoch \" +str(i))\n",
    "    plt.scatter(x=comps.components_[1],y=comps.components_[2])\n",
    "    plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: show the distribution of PC's across an epoch\n",
    "i = 0 \n",
    "for weight in weights_all_l1: \n",
    "    comps = pca.fit(weight)\n",
    "    plt.title(\"epoch \" +str(i))\n",
    "    plt.bar([i for i in range(10)],comps.explained_variance_ratio_[:10])\n",
    "    plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How much does the first PC explain across all the epochs? \n",
    "plt.plot(first_comp_ratios_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graphs in the cell above, this evolution makes sense. The final scatterplot of the first 2 PC's look like more disctinct components can draw from. \n",
    "\n",
    "Why is it that the 1st PC starts to be the dominant one again? Maybe take a look at the train/test accuracy across those epochs, maybe can see that overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance across the epochs\n",
    "It makes sense that variance is increasing. As the model learns to differentiate the inputs, activations will vary more and more to distinguish them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Given an [#epochs, #neurons, #inputs] matrix, creates an array of variance for each epoch. \n",
    "\"\"\"\n",
    "def calc_varaiance_across_epochs(all_weights): \n",
    "    variances = np.array([])\n",
    "    for w in all_weights: \n",
    "       #print(np.var(w))\n",
    "        variances = np.append(variances, (np.var(w)))\n",
    "    \n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(calc_varaiance_across_epochs(weights_all_l1), c='red')\n",
    "plt.plot(calc_varaiance_across_epochs(weights_all_l2), c='blue')\n",
    "plt.show()\n",
    "\n",
    "v1 = calc_varaiance_across_epochs(weights_all_l1) \n",
    "v1/=np.sqrt(np.sum(v1**2))\n",
    "v2 = calc_varaiance_across_epochs(weights_all_l2) / np.sqrt(np.sum(v1**2))\n",
    "v2 /= np.sqrt(np.sum(v2**2))\n",
    "plt.plot(v1, c='red')\n",
    "plt.plot(v2, c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2: 10 neurons, last dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "first_comp_ratios = []\n",
    "for weight in weights_all_l2: \n",
    "    comps = pca.fit(weight)\n",
    "    first_comp_ratios.append(comps.explained_variance_ratio_[0])\n",
    "    plt.title(\"epoch \" +str(i))\n",
    "    plt.scatter(x=comps.components_[1],y=comps.components_[2])\n",
    "    plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much does the first PC explain across all the epochs? \n",
    "plt.plot(first_comp_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wassup with Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "clustering = DBSCAN(eps=3, min_samples=2).fit(weights_e0_l1)\n",
    "clustering.labels_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "for i in weights_all_l1: \n",
    "    clustering = KMeans( n_clusters=10).fit(i)\n",
    "    print(silhouette_score(weights_e0_l1, clustering.labels_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mean we have the labels, we just wanna see a general overview of where they're ending up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "s(i) = (b(i) - a(i)) / max(a(i), b(i)). \n",
    "\n",
    "Where b(i) = average distance of point i to all points in nearest non-member cluster.   \n",
    "      a(i) = average distance of point i to all point in the same cluster.   \n",
    "      \n",
    "A score close to 0 means the clusters are relatively overlapping, or b(i) = a(i). This is fine usually but likely because of curse of dimenionality, these values are roughly equal when you wouldn't expect them to be. \n",
    "\n",
    "The values seem to be getting closer to 0, which means the distance within a cluster is increasing, supposedly more than the distance between clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Silhoutte scores for layer 1 \")\n",
    "for i in range(len(weights_all_l1)):\n",
    "    print(\"Epoch \", i, \": \", silhouette_score(weights_all_l1[i], test_labels[:500]))\n",
    "#silhouette_score(weights_e0_l1, test_labels[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Silhoutte scores for layer 2 \")\n",
    "for i in range(len(weights_all_l2)):\n",
    "    print(\"Epoch \", i, \": \", silhouette_score(weights_all_l2[i], test_labels[:500]))\n",
    "#silhouette_score(weights_e0_l1, test_labels[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silhouette_score(weights_e0_l1, test_labels[:500]))\n",
    "print(silhouette_score(weights_e1_l1, test_labels[:500]))\n",
    "print(silhouette_score(weights_e2_l1, test_labels[:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try: \n",
    "    - Precompute with silhouette: cosine, pearson\n",
    "    - Create similarity matrix and use MDS to project into 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score with Cosine Similarity\n",
    "The values don't seem to be changing too much to be significant, or are even still decreasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silhouette_score(weights_all_l1[0], test_labels[:500], metric=\"cosine\"))\n",
    "print(silhouette_score(weights_all_l1[1], test_labels[:500], metric=\"cosine\"))\n",
    "print(silhouette_score(weights_all_l1[2], test_labels[:500], metric=\"cosine\"))\n",
    "print(silhouette_score(weights_all_l1[3], test_labels[:500], metric=\"cosine\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(silhouette_score(weights_all_l2[0], test_labels[:500], metric=\"cosine\"))\n",
    "print(silhouette_score(weights_all_l2[1], test_labels[:500], metric=\"cosine\"))\n",
    "print(silhouette_score(weights_all_l2[2], test_labels[:500], metric=\"cosine\"))\n",
    "print(silhouette_score(weights_all_l2[3], test_labels[:500], metric=\"cosine\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score with Correlation\n",
    "Seem to be approximately the same as cosine, and similarly unhelpful trend/insights> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silhouette_score(weights_all_l1[0], test_labels[:500], metric=\"correlation\"))\n",
    "print(silhouette_score(weights_all_l1[1], test_labels[:500], metric=\"correlation\"))\n",
    "print(silhouette_score(weights_all_l1[2], test_labels[:500], metric=\"correlation\"))\n",
    "print(silhouette_score(weights_all_l1[3], test_labels[:500], metric=\"correlation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(silhouette_score(weights_all_l2[0], test_labels[:500], metric=\"correlation\"))\n",
    "print(silhouette_score(weights_all_l2[1], test_labels[:500], metric=\"correlation\"))\n",
    "print(silhouette_score(weights_all_l2[2], test_labels[:500], metric=\"correlation\"))\n",
    "print(silhouette_score(weights_all_l2[3], test_labels[:500], metric=\"correlation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections based on dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Makes an [n, n] matrix of dissimilarity scores from an [n, m] sized matrix where n samples has m features. \n",
    "    Possible metrics: \n",
    "        1. cosine (defualt): 1- cosine similarity\n",
    "\"\"\"\n",
    "def make_dissim_scores(samples, metric=\"cosine\"): \n",
    "    sim_matrix = np.array([])\n",
    "    if metric == \"cosine\": \n",
    "        sim_matrix = cosine_similarity(weights_e0_l1)\n",
    "        # Some rounding errors I think, but manually set the diagonal to be 1\n",
    "        # Not a great fix to the underlying issue though\n",
    "        for i in range(len(sim_matrix)): \n",
    "            sim_matrix[i][i] = round(sim_matrix[i][i])\n",
    "            sim_matrix[i] = (list(map(lambda x: 1-x, sim_matrix[i])))\n",
    "        return sim_matrix\n",
    "    #elif metric = \"pearson\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_all_l1 = np.array(list(map(lambda x: make_dissim_scores(x), weights_all_l1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed')\n",
    "weights_transform = mds.fit_transform(sims_all_l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in sims_all_l1:\n",
    "    weights_transform=mds.fit_transform(i)\n",
    "    plt.scatter(weights_transform[:,0], weights_transform[:,1], c=test_labels[:500])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(n_components=2, dissimilarity='cosine')\n",
    "\n",
    "for i in weights_all_l1:\n",
    "    weights_transform=mds.fit_transform(i)\n",
    "    plt.scatter(weights_transform[:,0], weights_transform[:,1], c=test_labels[:500])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(perplexity=90, n_components=2, init='random', n_iter=5000)\n",
    "lowD_1 = tsne.fit_transform(sims_all_l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lowD_1[:, 0],lowD_1[:, 1], c=test_labels[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne.set_params(metric=\"precomputed\")\n",
    "lowD_1_precomputed = tsne.fit_transform(sims_all_l1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lowD_1_precomputed[:, 0],lowD_1_precomputed[:, 1], c=test_labels[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood Comparison\n",
    "Seems to work better for the smaller layers, so I can't imagine the conv layers getting anything any better because their size will blow up even more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_e0_df = pd.DataFrame(weights_e0_l2)\n",
    "l2_e0_df[\"cluster\"] = test_labels[:500]\n",
    "l2_e0_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    make_sim_matrix is an [n_samples, n_samples] matrix of parwise similarities. \n",
    "    X: the [n_samples, n_features] matrix from which to genarate the similarities. \n",
    "    Method: the method for computing pairwise similarities. Default is cosine. If \"precomputed\", returns X. \n",
    "\"\"\"\n",
    "def make_sim_matrix(X, method=\"cosine\"):\n",
    "    sim_matrix = []\n",
    "    \n",
    "    if method == \"cosine\": \n",
    "        sim_matrix = np.array(cosine_similarity(X))\n",
    "    elif method == \"precomputed\":\n",
    "        sim_matrix = np.array(X)\n",
    "    \n",
    "    #ensure the diagonal is 1\n",
    "    for i in range(len(sim_matrix)): \n",
    "        sim_matrix[i][i] = round(sim_matrix[i][i])\n",
    "        #sim_matrix[i] = (list(map(lambda x: 1-x, sim_matrix[i])))\n",
    "        \n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    get_nh returns the neighborhood value of a point, ie the % of the k nearest points \n",
    "\n",
    "\"\"\"\n",
    "def get_nh(sim_matrix, feature_matrix, row_index, k=5):\n",
    "    row = feature_matrix.iloc[row_index, :]\n",
    "    # Remove any of the diagonal values\n",
    "    filtered = list(filter(lambda x: x!=1, sim_matrix[row_index]))\n",
    "    #Get the top k neighbors\n",
    "    top = np.sort(filtered)[-k:]\n",
    "    #print(top)\n",
    "    clusters = []\n",
    "    for i in range(len(sim_matrix[row_index])): \n",
    "        if sim_matrix[row_index][i] in top: \n",
    "            #rint(l2_e1_df.iloc[i, 10])\n",
    "            clusters.append(feature_matrix.iloc[i, -1])\n",
    "    #print(clusters)\n",
    "    # Get the cluster of the original vector\n",
    "    i_cluster = row[-1]\n",
    "    #print(row)\n",
    "    # Get the proprotion of the neighbors that are in the same cluster. \n",
    "    return len(list(filter(lambda x: x== i_cluster, clusters))) / len(clusters)\n",
    "\n",
    "def average_nh(feature_matrix):\n",
    "    sim_matrix = make_sim_matrix(feature_matrix.iloc[:, :10].values)\n",
    "    avg = 0\n",
    "    for i in range(len(feature_matrix)):\n",
    "        avg += get_nh(sim_matrix, feature_matrix, i)\n",
    "    return avg / len(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nh(l2_e0_sim, l2_e0_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_nh(l2_e0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in weights_all_l2: \n",
    "    df_i = pd.DataFrame(epoch)\n",
    "    df_i['cluster'] = test_labels[:500]\n",
    "    print(average_nh(df_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in weights_all_l1: \n",
    "    df_i = pd.DataFrame(epoch)\n",
    "    df_i['cluster'] = test_labels[:500]\n",
    "    print(average_nh(df_i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
